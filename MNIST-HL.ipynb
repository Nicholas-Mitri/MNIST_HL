{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST CLASSIFICATION WITH HIGH-LEVEL TF API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a demonstration of the high level Tensorflow API (tf.layers) as applied to the popular MNIST dataset. The following uses built-in layers to build a simple 3-layer DNN that classifies 28x28 images of hand-written digits from MNIST. \n",
    "\n",
    "We leverage the tensorflow example module to import the MNIST images as flattened vectors for easy processing. Batches of images are processed for multiple epochs while classification accuracy, training loss, and validation loss are logged and saved. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MNIST "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset is loaded from tf.examples for easy handling of training and validation data batching. Note that this is deprecated and will be removed in future versions of Tensorflow. Tf.data may be used alternatively to process the dataset and create an iterator similar to the one used here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-80aa5e208d67>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\users\\nicholas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\users\\nicholas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\nicholas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\nicholas\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we will use a simple DNN with 2 hidden layers. The network assumes the input is flattened. The choices of parameters like learning rate, number of epocks, and batch size are left for the user to experiment with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28*28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate =0.01\n",
    "n_epochs = 5\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(dtype=tf.int64, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "Three dense layers are created to process the handwritten digit data using the tf.layers module: Two hidden layers with RELU activations and one output linear layer. \n",
    "The logits at the output of the linear layer are then fed into a built-in cross entropy loss function that passes the logits through a softmax function and converts them into probabilities. \n",
    "Tf.summary is used to log the training and validation loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, name='hidden1', activation=tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name='hidden2', \n",
    "                              activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name='outputs')\n",
    "    \n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, \n",
    "                                                              logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "    loss_summary_1 = tf.summary.scalar(\"Loss_training\", loss)\n",
    "    loss_summary_2 = tf.summary.scalar(\"Loss_validation\", loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, k=1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "acc_summary = tf.summary.scalar(\"Validation_Accuracy\", accuracy)\n",
    "file_writer = tf.summary.FileWriter(\"./tf_log\", tf.get_default_graph())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the graph built, we create a TF session to train the network. For multiple epochs, mini batches of the data are fed to the graph, and accuracy is evaluated for training and validation. Validation accuracy, training loss, and validation loss are logged as well. \n",
    "Finally, TF.Saver is used to save the model and its parameters in .ckpt format in a user specified path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.98 Val accuracy: 0.904\n",
      "1 Train accuracy: 0.92 Val accuracy: 0.9224\n",
      "2 Train accuracy: 0.96 Val accuracy: 0.9338\n",
      "3 Train accuracy: 0.98 Val accuracy: 0.9394\n",
      "4 Train accuracy: 0.96 Val accuracy: 0.9424\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X:X_batch, y:y_batch})\n",
    "        \n",
    "        acc_train = accuracy.eval(feed_dict={X:X_batch, y:y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict={X:mnist.validation.images, \n",
    "                                          y:mnist.validation.labels})\n",
    "        \n",
    "        print(epoch, \"Train accuracy:\", acc_train, \"Val accuracy:\", acc_val)\n",
    "        \n",
    "        acc_str = acc_summary.eval(feed_dict={X:mnist.validation.images, \n",
    "                                          y:mnist.validation.labels})\n",
    "        tr_loss_str = loss_summary_1.eval(feed_dict={X:X_batch, y:y_batch})\n",
    "        ts_loss_str = loss_summary_2.eval(feed_dict={X:mnist.validation.images, \n",
    "                                          y:mnist.validation.labels})\n",
    "        \n",
    "        file_writer.add_summary(acc_str, epoch)\n",
    "        file_writer.add_summary(tr_loss_str, epoch)\n",
    "        file_writer.add_summary(ts_loss_str, epoch)\n",
    "\n",
    "        \n",
    "    save_path = saver.save(sess, \"./my_model_final_ckpt\")\n",
    "        \n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With training complate, we proceed to evaluating how the network performs on novel testing images. A random testing image is chosen and plotted. The model checkpoint is then restored and fed the test image. \n",
    "At the output of the network, the logits are computed and the max logit (corresponding to the highest probability) is chosen to label the input test image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final_ckpt\n",
      "The predicted label is  8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_img = np.random.randint(0, mnist.test.images.shape[0])\n",
    "plt.imshow(mnist.test.images[new_img].reshape(28,28), cmap='gray')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "   saver.restore(sess, \"./my_model_final_ckpt\")\n",
    "   X_new_scaled = mnist.test.images[new_img]\n",
    "   y_new_scaled = mnist.test.labels[new_img]\n",
    "   Z = logits.eval(feed_dict={X: X_new_scaled.reshape(-1,784)})\n",
    "   y_pred = np.argmax(Z, axis=1)\n",
    "\n",
    "print('The predicted label is ', y_pred[0]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
